{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectamos con la base de datos books.db\n",
    "connection = sqlite3.connect(\"books.db\")\n",
    "\n",
    "# Obtenemos un cursor que utilizaremos para hacer las queries\n",
    "crsr = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Con esta funci√≥n leemos los datos y lo pasamos a un DataFrame de Pandas\n",
    "# def sql_query(query):\n",
    "\n",
    "#     # Ejecuta la query\n",
    "#     crsr.execute(query)\n",
    "\n",
    "#     # Almacena los datos de la query \n",
    "#     ans = crsr.fetchall()\n",
    "\n",
    "#     # Obtenemos los nombres de las columnas de la tabla\n",
    "#     names = [description[0] for description in crsr.description]\n",
    "\n",
    "#     return pd.DataFrame(ans,columns=names)\n",
    "\n",
    "# query = '''\n",
    "# SELECT * \n",
    "# FROM books\n",
    "# '''\n",
    "\n",
    "\n",
    "# df = sql_query(query)\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.utils.fixes import linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U scikit-learn\n",
    "# %pip install --upgrade sklearn2pmml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures(degree=3)),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/advertising_model', 'rb') as archivo_entrada:\n",
    "    my_model = pickle.load(archivo_entrada)\n",
    "\n",
    "my_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TV = 'TV'\n",
    "\n",
    "\n",
    "args = {'TV':230, \n",
    "            'radio': 38,\n",
    "            'newspaper': 65}\n",
    "\n",
    "test = pd.DataFrame([args])\n",
    "\n",
    "\n",
    "predictions = my_model.predict(test)\n",
    "\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[21439.24523903]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predictions(tv, radio, newspaper):\n",
    "    # cargamos el modelo\n",
    "    # path_my_model = os.path.join(current_dir, 'model//my_model')\n",
    "    with open('data/advertising_model', 'rb') as archivo_entrada:\n",
    "        my_model = pickle.load(archivo_entrada)\n",
    "\n",
    "    # convertimos los datos de la llamada en test\n",
    "    # tv = int(request.args['tv'])\n",
    "    # radio = int(request.args['radio'])\n",
    "    # newspaper = int(request.args['newspaper'])\n",
    "\n",
    "    args = {'TV':tv,\n",
    "            'radio': radio,\n",
    "            'newspaper': newspaper}\n",
    "\n",
    "    test = pd.DataFrame([args])\n",
    "\n",
    "    # hacemos un predict\n",
    "    predictions = my_model.predict(test)\n",
    "\n",
    "    # return de predictions\n",
    "    return str(predictions)\n",
    "\n",
    "\n",
    "predictions(231, 38, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_train():\n",
    "    # cargamos los datos con los que vamos a entrenar el modelo\n",
    "    # path_train = os.path.join(current_dir, 'data//train.csv')\n",
    "    train = pd.read_csv('data/Advertising.csv', index_col=0)\n",
    "    print(train)\n",
    "    X= train.drop(columns=(['sales']))\n",
    "    y= train['sales']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20,random_state=42)\n",
    "\n",
    "    # cargamos el modelo\n",
    "    with open('data/advertising_model', 'rb') as archivo_entrada:\n",
    "        my_model = pickle.load(archivo_entrada)\n",
    "    \n",
    "    # reentrenamos\n",
    "    my_model.fit(X_train, y_train)\n",
    "\n",
    "    # # guardamos el modelo\n",
    "    # with open('data/trained_model', 'wb') as archivo_salida:\n",
    "    #     pickle.dump(my_model, archivo_salida)\n",
    "    \n",
    "    # sacamos las predicciones\n",
    "    predictions = my_model.predict(X_test)\n",
    "    mae = str(mean_absolute_error(y_test, predictions))\n",
    "    mape = str(mean_absolute_percentage_error(y_test, predictions))\n",
    "\n",
    "    return 'MAE: ' + mae, 'MAPE: ' + mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV  radio  newspaper    sales\n",
      "0    230.1   37.8       69.2  22100.0\n",
      "1     44.5   39.3       45.1  10400.0\n",
      "2     17.2   45.9       69.3   9300.0\n",
      "3    151.5   41.3       58.5  18500.0\n",
      "4    180.8   10.8       58.4  12900.0\n",
      "..     ...    ...        ...      ...\n",
      "195   38.2    3.7       13.8   7600.0\n",
      "196   94.2    4.9        8.1   9700.0\n",
      "197  177.0    9.3        6.4  12800.0\n",
      "198  283.6   42.0       66.2  25500.0\n",
      "199  232.1    8.6        8.7  13400.0\n",
      "\n",
      "[200 rows x 4 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('MAE: 388.68170485183674', 'MAPE: 0.03524411219291794')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18404\\973257664.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bed665d392a0b16c59368a0492a31cfeef380a776e0741f5d7e9c0d91554052a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
